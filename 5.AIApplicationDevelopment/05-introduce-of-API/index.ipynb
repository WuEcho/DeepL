{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API基础与通过API调用大模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## 💡 这节课会带给你\n",
    "\n",
    "1. 为什么需要API\n",
    "2. API的关键组成部分\n",
    "3. 如何通过API调用大模型\n",
    "4. 识别和处理调用时的常见错误\n",
    "5. 大批量调用的优化策略\n",
    "6. 应用场景代码样例实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 学习能力要求\n",
    "\n",
    "- 代码能力要求：中\n",
    "- AI/数学基础要求：无"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为什么我们需要API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在中大型开发项目实践中，我们往往需要构建和串联多个不同的功能模块，但这些功能模块可能会使用不同的语言来进行实现，或是虽然使用了相同的语言来实现，但不归属于同一个环境，导致无法直接进行数据交换、功能调用。\n",
    "\n",
    "API（应用程序编程接口，Application Programming Interface）是不同软件组件之间进行交互和通信的接口，它允许不同的应用程序或服务相互调用和交换数据。可以把API看作是软件之间的桥梁，让它们能够“谈话”并共享功能。\n",
    "\n",
    "API是复杂开发项目中进行模块串联的关键构件，它能够让我们无视掉不同功能模块的具体实现，着眼于基于项目需要的架构规划、模块调用关系、数据流动进行设计。\n",
    "\n",
    "常见场景：\n",
    "\n",
    "- 前后端通讯：使用JS的前端脚本和使用JAVA的业务后端服务通讯\n",
    "- 服务间通讯：使用Python的算法服务和使用Golang的业务后端服务通讯\n",
    "- 跨服务商通讯：业务后端服务通过网络直接请求服务商提供的API，完成如大模型请求、订单查询、天气查询等操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API的关键组成部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以OpenAI的对话补全接口为例，接口说明文档地址：https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 请求部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 端点/路径（Endpoints/Path）\n",
    "\n",
    "端点是API的“入口”，它是你与API交互的具体路径，OpenAI的对话补全接口端点是：/v1/chat/completions\n",
    "\n",
    "端点的作用：\n",
    "\n",
    " - 帮助API服务做版本管理\n",
    " - 标识功能或资源，直观展现层级关系\n",
    "\n",
    "举例：\n",
    "\n",
    "- `https://examples.com/v1/users/info/{user_id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请求方法（Methods）\n",
    "\n",
    "常见的API大多基于HTTP协议，通过HTTP协议的标准请求方法来区分API的操作类型\n",
    "\n",
    "- PUT：更新数据（修改操作）Create\n",
    "- GET：请求数据（读取操作）Read\n",
    "- POST：提交数据（创建操作）Update\n",
    "- DELETE：删除数据（移除操作）Delete\n",
    "\n",
    "> 注：还有一个不太常见的方法：PATCH - 部分修改，和PUT - 全量修改对应，但是实践中PUT一般就等于修改，不区分部分还是全量了\n",
    "\n",
    "不同请求方法携带数据的方式也有区别，这一点在下面的《请求参数》部分再加以介绍\n",
    "\n",
    "举例：\n",
    "\n",
    "- `PUT https://examples.com/v1/users/info/{user_id}`\n",
    "- `GET https://examples.com/v1/users/info/{user_id}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请求参数（Parameters）\n",
    "\n",
    "通常我们会把和API对应功能相关的数据放在请求中进行传递，以实现在对同一个API接口的请求时，能够操作不同的资源对象，或是对操作的细节进行控制。\n",
    "\n",
    "常见的请求参数类型有：\n",
    "\n",
    "- 路径参数（Path Parameters）：直接嵌入在请求端点路径里的参数，比如上面的`{user_id}`\n",
    "- 查询参数（Query Parameters）：查询参数通常会被放在URL的?之后，比如Serper提供的搜索API就支持使用这样的参数`https://google.serper.dev/search?q=zhihu&apiKey=xxxxxxxxxxxxxx`\n",
    "- 请求体（Request Body）：请求体通常会被放在请求内部，在URL上不直接可见\n",
    "\n",
    "不同参数的区别：\n",
    "\n",
    "- 路径参数（Path Parameters）和查询参数（Query Parameters）会直接体现在URL上，数据传递长度受到URL长度的限制，比如Apache和Nginx的默认限制URL长度为8192字符，现代浏览器支持的URL长度限制在2000到8000字符之间，对于大数据量传递或是因为安全考虑需要对数据进行加密而造成的字符长度增加都不合适\n",
    "- 通常而言请求体（Request Body）默认支持的数据长度更长，比如Apache默认就不对RequestBody长度进行限制，Nginx默认为1M，Express.js默认为100K，现代浏览器通常支持大约4GB的数据请求长度，对于更大体量的数据传递，我们通常就要考虑使用流式数据传输的方式将数据切成更小的数据块（chunk），而不是一次性传递了，这在今天的课程中就不展开讨论了。\n",
    "\n",
    "不同请求方法使用的请求参数\n",
    "\n",
    "- GET、DELETE方法：通常只能使用路径参数（Path Parameters）和查询参数（Query Parameters）\n",
    "- PUT、POST方法：通常能使用上述全部三种参数，并且通常都会将业务数据结构化，放入请求体（Request Body）进行传递，部分敏感数据还要使用双向加密技术进行加密后传递"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 请求头（Headers）\n",
    "\n",
    "如果说请求参数主要负责传递和业务操作相关的信息，那么请求头就更多负责传递与请求本身相关的元信息，例如通用请求头就有以下常见作用：\n",
    "\n",
    "- 类型说明：\n",
    "    - Content-Type：说明本次请求传递的请求数据体类型，常见值如：\n",
    "        - `text/plain`：纯文本型数据\n",
    "        - `application/x-www-form-urlencoded`：通过页面表单（HTML中的`<form>`标签）传递的数据\n",
    "        - `application/json`：JSON格式的数据\n",
    "        - `application/xml`：XML格式的数据\n",
    "\n",
    "    - Accept：说明本次请求接收的响应体格式，帮助服务端根据此内容决定返回值的数据格式，常见值如：\n",
    "        - `*/*`：说明可以接收任何格式的返回结果\n",
    "        - `text/html`：说明期望接收的返回结果是一个HTML格式的网页内容\n",
    "        - `text/plian`：说明期望接收的返回结果是纯文本内容\n",
    "        - `application/json`：说明期望接收的返回结果是JSON格式的数据\n",
    "        - `application/xml`：说明期望接收的返回结果是XML格式的数据\n",
    "        - `image/jpeg`、`image/png`、`image/gif`：说明期望接收的返回结果是指定类型的图片\n",
    "\n",
    "    > 注：类型说明请求头对于不同语言的请求包也有很大作用，大部分请求包都为常见的请求和接收格式做了格式校验和转义的便捷功能\n",
    "\n",
    "- 身份标记及认证：\n",
    "    - User-Agent：说明本次请求的客户端软件标识，通常是浏览器或者应用程序名称（服务端模拟浏览器爬取网页信息时也会使用），例如：`User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36`\n",
    "    - Authorization：请求中携带的认证信息，例如目前各大模型接口，尤其是OpenAI-Like格式模型接口的认证方式，就是使用Bearer Token的方式，将API-Key放在该请求头中，例如：`Authorization: Bearer sk-xxxxxxxx`\n",
    "\n",
    "    常见身份认证方式相关扩展阅读\n",
    "    * API-Key：直接明文放入请求头中，如果使用请求抓包工具，容易被抓获，适合跨服务商的服务端-服务端请求，不适合客户端直接请求（浏览器可以直接看到明文API-Key造成信息泄露）\n",
    "    * OAuth 2.0：官方说明文档：https://oauth.net/2/ ，核心思想如下图，即客户端通过原始授权信息（如用户名、密码）询问资源所有者获取资源访问许可（通常是一个有效时长很短的许可），使用该需求向授权服务器获取授权令牌（Access Token），后续通过授权令牌访问资源。这么设计的好处是在资源访问时（通常都是大量的网络请求）不会暴露用户名、密码，只会暴露令牌，令牌通过其他校验机制（比如过期校验、客户端ID哈希校验等）来确保可信。\n",
    "\n",
    "    ```text\n",
    "     +--------+                               +---------------+\n",
    "     |        |--(A)- Authorization Request ->|   Resource    |\n",
    "     |        |                               |     Owner     |\n",
    "     |        |<-(B)-- Authorization Grant ---|               |\n",
    "     |        |                               +---------------+\n",
    "     |        |\n",
    "     |        |                               +---------------+\n",
    "     |        |--(C)-- Authorization Grant -->| Authorization |\n",
    "     | Client |                               |     Server    |\n",
    "     |        |<-(D)----- Access Token -------|               |\n",
    "     |        |                               +---------------+\n",
    "     |        |\n",
    "     |        |                               +---------------+\n",
    "     |        |--(E)----- Access Token ------>|    Resource   |\n",
    "     |        |                               |     Server    |\n",
    "     |        |<-(F)--- Protected Resource ---|               |\n",
    "     +--------+                               +---------------+\n",
    "    ```\n",
    "    * JWT：官方说明文档：https://jwt.io/ ，核心思路是将加密算法名、Token类型放入头部（Header）密文，加密数据本体放入负载（Payload）密文，验证签名放入签名（Signature）密文，将三段密文整合成一个密文体，与双向加密的公私钥配合，实现轻量级自包含（即所有与加解密相关的信息都在密文中）的验证方式。Python中提供了PyJWT库来验证JWT："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sub': '1234567890', 'name': 'John Doe', 'iat': 1516239022}\n",
      "Token已过期\n"
     ]
    }
   ],
   "source": [
    "import jwt\n",
    "from datetime import datetime\n",
    "\n",
    "# 假设这是服务器上的密钥\n",
    "SECRET_KEY = 'your-256-bit-secret'\n",
    "\n",
    "# 获取JWT token\n",
    "token = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6IkpvaG4gRG9lIiwiaWF0IjoxNTE2MjM5MDIyfQ.SflKxwRJSMeKKF2QT4fwpMeJf36POk6yJV_adQssw5c'\n",
    "\n",
    "try:\n",
    "    # 验证并解码JWT\n",
    "    decoded_token = jwt.decode(token, SECRET_KEY, algorithms=[\"HS256\"])\n",
    "\n",
    "    # 查看消息体内容\n",
    "    print(decoded_token)\n",
    "    # 检查过期情况\n",
    "    if decoded_token['iat'] < datetime.now().timestamp():\n",
    "        raise jwt.ExpiredSignatureError(\"Token expired\")\n",
    "    \n",
    "    print(\"JWT验证成功:\", decoded_token)\n",
    "except jwt.ExpiredSignatureError:\n",
    "    print(\"Token已过期\")\n",
    "except jwt.InvalidTokenError:\n",
    "    print(\"无效的Token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 自定义请求头：\n",
    "    \n",
    "    HTTP请求协议支持用户自定义更多请求头，但为了和标准请求头有所区分，通常建议使用`X-`的方式进行命名\n",
    "\n",
    "    例如，如果你想要通过请求头传递用户的ID信息，可以用这个方式定义一个新的请求头：`X-User-Id: 12345`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 响应部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 状态码（Status Codes）\n",
    "\n",
    "API请求的响应会包含一个HTTP状态码，状态码能够帮助我们最快理解本次请求的处理结果状态，常见的状态码说明：\n",
    "\n",
    "- 200 OK：请求成功，服务器返回请求的数据。\n",
    "- 201 Created：请求成功，并且已创建资源（常见于POST请求）。\n",
    "- 400 Bad Request：请求格式错误，服务器无法理解。\n",
    "- 401 Unauthorized：请求未授权，可能缺少有效的认证信息。\n",
    "- 404 Not Found：请求的资源不存在。\n",
    "- 500 Internal Server Error：服务器出错，无法处理请求。\n",
    "\n",
    "> 注：响应状态码和API接口请求返回的数据体中可能包含的`status`字段不一样，响应状态码通常由提供API的服务框架决定，遵从HTTP规范，每一个状态码值都有对应的共识的含义，正常情况下不应更改，如我们不会使用200表示请求失败，也不会用404表示格式错误"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 响应体（Response Body）\n",
    "\n",
    "与请求体（Request Body）对应，API请求的主要业务数据返回结果都会被放在响应体（Response Body）中，响应体的内容格式和通常和请求头`Accept`要求的格式一致，也通常会在API说明文档中明确。\n",
    "\n",
    "例如，OpenAI的对话补全接口给出的响应体结构如下：\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"chatcmpl-123\",\n",
    "  \"object\": \"chat.completion\",\n",
    "  \"created\": 1677652288,\n",
    "  \"model\": \"gpt-4o-mini\",\n",
    "  \"system_fingerprint\": \"fp_44709d6fcb\",\n",
    "  \"choices\": [{\n",
    "    \"index\": 0,\n",
    "    \"message\": {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"\\n\\nHello there, how may I assist you today?\",\n",
    "    },\n",
    "    \"logprobs\": null,\n",
    "    \"finish_reason\": \"stop\"\n",
    "  }],\n",
    "  \"usage\": {\n",
    "    \"prompt_tokens\": 9,\n",
    "    \"completion_tokens\": 12,\n",
    "    \"total_tokens\": 21,\n",
    "    \"completion_tokens_details\": {\n",
    "      \"reasoning_tokens\": 0,\n",
    "      \"accepted_prediction_tokens\": 0,\n",
    "      \"rejected_prediction_tokens\": 0\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```\n",
    "显然，这是一个JSON格式的响应体返回结果，也是目前最常见的响应体返回格式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API的调用实践"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一起再来读读OpenAI的接口文档\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat/create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 终端指令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "curl -x http://127.0.0.1:7890 \\\n",
    "  https://api.openai.com/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n",
    "  -d '{\n",
    "    \"model\": \"gpt-4o\",\n",
    "    \"messages\": [\n",
    "      {\n",
    "        \"role\": \"developer\",\n",
    "        \"content\": \"You are a helpful assistant.\"\n",
    "      },\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello!\"\n",
    "      }\n",
    "    ]\n",
    "  }'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python请求"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!pip install httpx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **为什么选择httpx？**\n",
    ">\n",
    "> httpx是目前最常用的大模型请求客户端openai客户端的网络请求核心依赖包\n",
    "> 熟悉httpx的使用，对于未来自定义openai客户端的网络请求部分有很大帮助\n",
    "> \n",
    "> httpx官方网站：https://www.python-httpx.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'{\\n  \"id\": \"chatcmpl-B4Aoj2z9rbiKXDRVYQqt6r0LlBo9g\",\\n  \"object\": \"chat.completion\",\\n  \"created\": 1740334593,\\n  \"model\": \"gpt-4o-mini-2024-07-18\",\\n  \"choices\": [\\n    {\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": \"Hello! How can I assist you today?\",\\n        \"refusal\": null\\n      },\\n      \"logprobs\": null,\\n      \"finish_reason\": \"stop\"\\n    }\\n  ],\\n  \"usage\": {\\n    \"prompt_tokens\": 19,\\n    \"completion_tokens\": 10,\\n    \"total_tokens\": 29,\\n    \"prompt_tokens_details\": {\\n      \"cached_tokens\": 0,\\n      \"audio_tokens\": 0\\n    },\\n    \"completion_tokens_details\": {\\n      \"reasoning_tokens\": 0,\\n      \"audio_tokens\": 0,\\n      \"accepted_prediction_tokens\": 0,\\n      \"rejected_prediction_tokens\": 0\\n    }\\n  },\\n  \"service_tier\": \"default\",\\n  \"system_fingerprint\": \"fp_7fcd609668\"\\n}\\n'\n",
      "{'id': 'chatcmpl-B4Aoj2z9rbiKXDRVYQqt6r0LlBo9g', 'object': 'chat.completion', 'created': 1740334593, 'model': 'gpt-4o-mini-2024-07-18', 'choices': [{'index': 0, 'message': {'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None}, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 19, 'completion_tokens': 10, 'total_tokens': 29, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': 'default', 'system_fingerprint': 'fp_7fcd609668'}\n",
      "{'role': 'assistant', 'content': 'Hello! How can I assist you today?', 'refusal': None}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "response = httpx.post(\n",
    "    \"https://api.openai.com/v1/chat/completions\",\n",
    "    headers={\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer { os.environ['OPENAI_API_KEY'] }\",\n",
    "    },\n",
    "    json={\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": \"You are a helpful assistant.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Hello!\"\n",
    "        }\n",
    "        ],\n",
    "    },\n",
    "    proxy=\"http://127.0.0.1:7890\",\n",
    ")\n",
    "print(response.status_code) #状态码\n",
    "print(response.content)   #响应体\n",
    "response_data = json.loads(response.content.decode()) #转义后的字典\n",
    "print(response_data)\n",
    "print(response_data[\"choices\"][0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import openAI\n",
    "\n",
    "client = openAI(\n",
    "    api_key = os.environ['DEEPSEEK_API_KEY'],\n",
    "    base_url = \"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    message = [\n",
    "        {\"role\":\"system\",\"content\":\"You are a helpful assistant\"},\n",
    "        {\"role\":\"user\",\"content\":\"Hello\"},\n",
    "    ],\n",
    "    stream = True    \n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content,end=\"\",flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 批量调用策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./batches.drawio.png\" width=\"340\" height=\"auto\" style=\"display: block; margin-left: auto; margin-right: auto; border-radius: 8px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "讨论点：\n",
    "\n",
    "- 选择异步还是多线程？\n",
    "- 是否可以容忍延时返回？\n",
    "- 批量任务中出现重复或者错误怎么办？\n",
    "- 并发量太大，出现接口速率限制问题怎么办？\n",
    "\n",
    "动手试一试：\n",
    "\n",
    "- 以免费模型API接口为例，开发并发代码样例\n",
    "- 了解Batch接口：https://platform.openai.com/docs/guides/batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熟悉python的异步协程运行机制：\n",
    "    \n",
    ">\n",
    "> 扩展阅读：Python官方文档-Asynchronous I/O https://docs.python.org/zh-cn/3.13/library/asyncio.html\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在 jupyter 环境中需要使用下面的方法消除loop冲突\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import httpx\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "async def async_model_request(user_input):\n",
    "    #async with httpx.Client(proxy=\"http://127.0.0.1:7890\") as client: #异步创建一个客户端在本代码块区域有效 本地运行需要配置proxy\n",
    "    async with httpx.Client() as client:\n",
    "        response = await client.post(                                 #允许让渡\n",
    "             \"https://api.openai.com/v1/chat/completions\",\n",
    "             headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer { os.environ['OPENAI_API_KEY'] }\",\n",
    "             },\n",
    "             json = {\n",
    "                  \"model\": \"gpt-4o-mini\",\n",
    "                  \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"developer\",\n",
    "                        \"content\": \"You are a helpful assistant.\"\n",
    "                     },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ],\n",
    "             }\n",
    "        )\n",
    "        print(response.status_code)\n",
    "        print(response.content)\n",
    "        if response.status_code == 200:\n",
    "            response_data = json.load(response.content.decode())\n",
    "            print(response_data)\n",
    "            print(response_data[\"choices\"][0][\"message\"])\n",
    "        else:\n",
    "            response_data = json.load(response.content.decode())\n",
    "            print(response_data[\"error\"])   \n",
    "\n",
    "asyncio.run(async_model_request(\"Hello\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 并发进行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def concurrent_request(question_list):\n",
    "    task = []\n",
    "    for question in question_list:\n",
    "        task.append(asyncio.create_task(async_model_request(question)))\n",
    "    await asyncio.gather(*task)\n",
    "\n",
    "asyncio.run(concurrent_request([\n",
    "    \"Hello\",\n",
    "    \"How are you\",\n",
    "    \"Who are you\",\n",
    "    \"How is weather today?\",\n",
    "    \"Are you a AI human being?\",\n",
    "]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 错误处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在 jupyter 环境中需要使用下面的方法消除loop冲突\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "import httpx\n",
    "import json\n",
    "import asyncio\n",
    "\n",
    "async def async_model_request(user_input):\n",
    "    #async with httpx.Client(proxy=\"http://127.0.0.1:7890\") as client: #异步创建一个客户端在本代码块区域有效 本地运行需要配置proxy\n",
    "    async with httpx.Client() as client:\n",
    "        response = await client.post(                                 #允许让渡\n",
    "             \"https://api.openai.com/v1/chat/completions\",\n",
    "             headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Authorization\": f\"Bearer { os.environ['OPENAI_API_KEY'] }\",\n",
    "             },\n",
    "             json = {\n",
    "                  \"model\": \"gpt-4o-mini\",\n",
    "                  \"messages\": [\n",
    "                    {\n",
    "                        \"role\": \"developer\",\n",
    "                        \"content\": \"You are a helpful assistant.\"\n",
    "                     },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": user_input\n",
    "                    }\n",
    "                ],\n",
    "             }\n",
    "        )\n",
    "        print(response.status_code)\n",
    "        print(response.content)\n",
    "        if response.status_code == 200:\n",
    "            response_data = json.load(response.content.decode())\n",
    "            print(response_data)\n",
    "            print(response_data[\"choices\"][0][\"message\"])\n",
    "            return response_data[\"choices\"][0][\"message\"]\n",
    "        else:\n",
    "            response_data = json.load(response.content.decode())\n",
    "            error = RuntimeError(response_data[\"error\"])\n",
    "            error.status_code = response.status_code\n",
    "            error.error_content = response_data[\"error\"]\n",
    "            raise error\n",
    "\n",
    "try:\n",
    "    print(asyncio.run(async_model_request(\"Hello\")))\n",
    "except RuntimeError as e:\n",
    "    print(e)\n",
    "    print(e.status_code)\n",
    "    print(e.error_content)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 常见错误码：\n",
    "> 401 : 错误的授权信息(通常是api key错误)\n",
    "> 404 : 找不到资源(通常是写错url或写错参数)\n",
    "> 429 : 超出速率限制(在响应头中有可能可以找到Retry-After字段来提供再次重试需要等待的时间信息)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 给批量请求加入批次处理等待和容错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def concurrent_request(question_list,batch_length=2,interval = 1):\n",
    "    all_requests = []\n",
    "    err_tasks = []\n",
    "    start_pos = 0\n",
    "    end_pos = batch_length if batch_length < len(question_list) else len(question_list) -1\n",
    "    while start_pos < len(question_list):\n",
    "        current_batch = question_list[start_pos:end_pos]\n",
    "        current_task = []\n",
    "        for question in current_batch:\n",
    "            current_task.append(asyncio.create_task(async_model_request(question)))\n",
    "        results = await asyncio.gather(*current_task,return_exceptions=True)\n",
    "        for index,result in enumerate(results):\n",
    "            if isinstance(result,RuntimeError):\n",
    "                err_tasks.append((current_batch[index],result))\n",
    "            all_requests.append((current_batch[index],result))\n",
    "        start_pos += batch_length\n",
    "        end_pos += batch_length\n",
    "        await asyncio.sleep(interval)  # 让渡控制权\n",
    "    print(all_requests)\n",
    "    print(err_tasks)        \n",
    "\n",
    "asyncio.run(concurrent_request([\n",
    "    \"Hello\",\n",
    "    \"How are you\",\n",
    "    \"Who are you\",\n",
    "    \"How is weather today?\",\n",
    "    \"Are you a AI human being?\",\n",
    "],2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于大模型API的实际应用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 命令行多轮对话"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "def request_model(messages):\n",
    "    response = httpx.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer { os.environ['OPENAI_API_KEY'] }\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": messages,\n",
    "        },\n",
    "        proxy=\"http://127.0.0.1:7890\",\n",
    "    )\n",
    "    response_data = json.loads(response.content.decode())\n",
    "    return response_data[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型不会存储对话记录，因此需要我们自己进行对话记录的保存\n",
    "messages = []\n",
    "while True:\n",
    "    user_input = input(\"[User]:\")\n",
    "    if user_input == \"#exit\":\n",
    "        break\n",
    "    messages.append({ \"role\": \"user\", \"content\": user_input })\n",
    "    reply = request_model\n",
    "    print(f\"[Assistant]: {reply}\")\n",
    "    messages.append({ \"role\": \"assistant\", \"content\": reply })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 文本分析、意图分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import httpx\n",
    "import json\n",
    "\n",
    "def request_model(prompt, role=None):\n",
    "    messages = []\n",
    "    if role:\n",
    "        messages.append({\n",
    "            \"role\": \"developer\",\n",
    "            \"content\": role,\n",
    "        })\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "    })\n",
    "    response = httpx.post(\n",
    "        \"https://api.openai.com/v1/chat/completions\",\n",
    "        headers={\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"Authorization\": f\"Bearer { os.environ['OPENAI_API_KEY'] }\",\n",
    "        },\n",
    "        json={\n",
    "            \"model\": \"gpt-4o-mini\",\n",
    "            \"messages\": messages,\n",
    "        },\n",
    "        proxy=\"http://127.0.0.1:7890\",\n",
    "    )\n",
    "    response_data = json.loads(response.content.decode())\n",
    "    return response_data[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 用户意图：申请退款\n",
      "- 关键信息：\n",
      "    - 产品：酸奶\n",
      "    - 状态：坏了\n",
      "    - 请求：退款\n"
     ]
    }
   ],
   "source": [
    "role = \"你是一个客服机器人，需要理解<target_text>标签中的问题，并按照<requirement>标签的要求给出回复\"\n",
    "prompt = \"\"\"\n",
    "<target_text>\n",
    "您好，我昨天买的酸奶好像坏了，请问可以退款吗？\n",
    "</target_text>\n",
    "<requirement>\n",
    "请识别用户的意图，并给出与该意图相关的关键信息\n",
    "例如：\n",
    "- 用户意图：闲聊\n",
    "- 关键信息：\n",
    "    - 话题：出行计划\n",
    "</requirement>\n",
    "\"\"\"\n",
    "print(request_model(prompt, role=role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌入自己的业务系统：构建自己的API服务\n",
    "#### 使用FastAPI框架\n",
    "安装方法：pip install fastapi\n",
    "官方文档：[https://fastapi.tiangolo.com/](https://fastapi.tiangolo.com/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  启动一个简单的FastAPI 服务\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI,WebSocket\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/test\") #http://127.0.0.1:8000/test\n",
    "async def test():\n",
    "    return {\n",
    "        \"status\":True,\n",
    "        \"data\":\"it works\",\n",
    "        \"err\":None,\n",
    "    }\n",
    "\n",
    "@app.websocket(\"/ws\")  #ws://127.0.0.1:8000/ws\n",
    "async def chat(websocket :WebSocket):\n",
    "    await websocket.accept()\n",
    "    data = await websocket.receive_text()\n",
    "    await websocket.send_json({\n",
    "        \"status\":True,\n",
    "        \"data\":data,\n",
    "        \"err\":None,\n",
    "    })\n",
    "    await websocket.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面这段代码不能再脚本中运行，需要配合FastApi的服务器管理uvicorn进行启动。\n",
    "例如，项目文件目录为：\n",
    "    my_project/\n",
    "    |\n",
    "    |-- app/\n",
    "    |   |-- __init__.py\n",
    "    |   |-- main.py (内容为上面的代码)\n",
    "    |-----命令行所在位置\n",
    "\n",
    "通过安装Fastapi是自动安装的uvicorn(如没有安装，可手动安装`pip install uvicorn`)启动\n",
    "命令为：`uvicorn app.main:app`\n",
    "可选参数：\n",
    "     - --host 0.0.0.0\n",
    "     - --port 8080\n",
    "     - --reload   #监听代码修改内容无需重启服务\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 衍生知识\n",
    "与FastAPI配合的性能监控\n",
    "\n",
    "- Prometheus\n",
    "    - 安装方法：`brew install prometheus`\n",
    "    - 引入FastAPI监控插件：\n",
    "    ```\n",
    "    pip install prometheus_fastapi_instrumentator\n",
    "\n",
    "    from prometheus_fastapi_instrumentator import Instrumentator\n",
    "    instrumentator = Instrumentator()\n",
    "    instrumentator.instrument(app).expose(app,endpoint=\"/performance\")\n",
    "    ```\n",
    "    - 修改prometheus的配置文件，将监控端点引入数据监听\n",
    "    以`Homebrew`安装为例，配置文件在`/opt/homebrew/etc/prometheus.yml`\n",
    "    在`scrape_configs`中加入：\n",
    "   \n",
    "   ```\n",
    "    - job_name:\"fastapi\"\n",
    "      static_configs:\n",
    "      - targets: [\"localhost:8080\"]\n",
    "      metrics_path:\"performance\"\n",
    "   ```\n",
    "\n",
    "   - 通过Homebrew启动prometheus服务：`brew services start prometheus`\n",
    "   - 可以在默认地址`127.0.0.1:9090`看到prometheus页面，输入`query`查询即可\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
