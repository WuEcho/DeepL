# NLP基础-分词

## 分词任务

- 为什么要分词?

1. 分词是一个长期研究的任务,通过了解分词算法的发展,可以看到NLP的研究历程
2. 分词是nlp中一类问题的代表
3. 分词很常用，很多NLP任务建立在分词之上


 ## 中文分词的难点
 
- 歧义切分：    - 南京市长江大桥    - 欢迎新老师生前来就餐    - 无线电法国别研究    - 乒乓球拍卖完了
     - 新词/专有名词/改造词等：     - 九漏鱼     - 活性位点、受体剪切位点     - 虽迟但到、十动然拒

 ## 中文分词 - 正向最大匹配
 
### 分词步骤：1. 收集一个词表2. 对于一个待分词的字符串，从前向后寻找最长的，在此表中出现的词，在词边界做切分3. 从切分处重复步骤2，直到字符串末尾- 词表：                                         北京   /          生前                         北京大学 /        前来                         大学     /        报到大学生
 
- 句子：
北京大学生前来报到
 - 根据上面的句子利用词表进行分词结果如下：
   北京大学 / 生前 / 来 / 报到
   
### 实现方式

#### 实现方式一1. 找出词表中最大词长度2. 从字符串开头开始选取最大词长度的窗口，检查窗口内的词是否在词表中3. 如果在词表中，在词边界处进行切分，之后移动到词边界处，重复步骤24. 如果不在词表中，窗口右边界回退一个字符，之后检查窗口词是否在词表中   
##### 切分过程
<u>北 京 大 学</u> 生 前 来 报 到 -- 查看四个字是否是一个词，是，进行切分北 京 大 学 <u>生 前 来 报</u> 到 -- 查看四个字是否是一个词，不是向前回退北 京 大 学 <u>生 前 来</u> 报 到 -- 查看三个字是否是一个词北 京 大 学 <u>生 前</u> 来 报 到 -- 查看两个字是否是一个词北 京 大 学 生 前 <u>来 报 到</u> 北 京 大 学 生 前 <u>来 报</u> 到北 京 大 学 生 前 <u>来</u> 报 到北 京 大 学 生 前 来 <u>报 到</u>#### 实现方式二
利用前缀字典1. 从前向后进行查找2. 如果窗口内的词是一个词前缀则继续扩大窗口3. 如果窗口内的词不是一个词前缀，则记录已发现的词，并将窗口移动到词边界- 词表：北京北京大学北京大学生大学生

```
0代表不是一个词，但是是词的前缀1代表是一个词
{  "北": 0,  "北京": 1,  "北京大": 0,  "北京大学": 1,  "北京大学生": 1,  "大": 0,  "大学": 0,  "大学生": 1}
```   

#### 切分过程

<u>北 京</u> 大 学 生 前 来 报 到 —— 从’北‘字开始向前缀词典中进行寻找，发现是某个词的前缀，继续，找到’北京‘，然后继续向后查找<u>北 京 大 学</u> 生 前 来 报 到 —— 找到’北京大‘以后在前缀词典中发现是前缀，继续查找，找到'北京大学'，也是一个词，继续向后找
<u>北 京 大 学 生</u> 前 来 报 到 —— 直到找到'北京大学生' 进行切分<u>北 京 大 学</u> 生 前 来 报 到 —— 假设词表里面没有’北京大学生‘，则在'生'字前进行切分北 京 大 学 <u>生 前</u> 来 报 到 —— 假设'生前'即不是一个词的前缀，也不是一个词的话，即停止不再向后查看北 京 大 学 <u>生 前 来</u> 报 到北 京 大 学 <u>生 前</u> 来 报 到北 京 大 学 生 前 <u>来 报</u> 到北 京 大 学 生 前 <u>来</u> 报 到以上两种方法代码实现可参考：

>
> note ：针对这两种方法都需要使用到信息文本：corpus.txt
> 以及节八字典：dict.txt(以空格进行分割)
>

实现方法1：[forward_segmentation_method1.py](./code/forward_segmentation_method1.py)

实现方法2：[forward_segmentation_method2.py](./code/forward_segmentation_method2.py)

## 中文分词 —— 反向最大匹配
基于相同的词表从右向左进行切词；

          北 京 大 学 生 前 来 报 到正向匹配：    北京大学 /  生前 / 来 / 报到反向匹配：     北京 / 大学生 / 前来 / 报到## 中文分词 —— 双向最大匹配 

同时进行正向最大切分，和负向最大切分，之后比较两者结果，决定切分方式。- 如何比较是正向切分的结果好还是反向切分的结果好？1. 单字词          词表中可以有单字，从分词的角度，我们也会把它称为一个词2. 非字典词          未在词表中出现过的词，一般都会被分成单字3. 词总量           不同切分方法得到的词数可能不同
### 双向最大匹配的示例
- 我们在野生动物园玩- 词表：我们/在野/生动/动物/野生动物园/野生/动物园/在/玩/园
    - 正向最大匹配法：“我们/在野/生动/物/园/玩”词典词3个，单字字典词为2，非词典词为1。    - 逆向最大匹配法：“我们/在/野生动物园/玩”词典词2个，单字字典词为2，非词典词为0。结论：通常来说，从中文分词的结果来看，切分的词总量越少越好，单字词越少越好,非词典词越少越好

## 中文分词 —— jieba分词
jieba是python的第三方库，可以使用”pip install jieba“进行安装；
```python
import jieba

jieba.cut(stringInfo)
```

- 分词原理
根据词表对一个文本内容进行全切分，计算哪种切分方式总词频最高，词频事先根据分词后语料统计出来

- 分词语料：北京大学生前来报到
    
     - 词表：北京/大学/北京大学/大学生/生前/前来/报到
    
#1：北京 / 大学 / 生 / 前来 / 报到#2：北京大学 / 生 / 前来 / 报到#3：北京 / 大学生 / 前来 / 报到#4：北京 /大学 / 生前 / 来 / 报到#5：北京大学 / 生前 / 来 / 报到## 中文分词的问题

- 正向最大切分，负向最大切分，双向最大切分**共同的缺点**：1. 对词表极为依赖，如果没有词表，则无法进行；如果词表中缺少需要的词，结果也不会正确2. 切分过程中不会关注整个句子表达的意思，只会将句子看成一个个片段3. 如果文本中出现一定的错别字，会造成一连串影响4. 对于人名等的无法枚举实体词无法有效的处理## 中文分词 —— 基于机器学习

- 重新思考，如果想要对一句话进行分词，我们需要什么知道什么？                     上 海 自 来 水 来 自 海 上对于每一个字，我们想知道它是不是一个词的边界                 上 | 海 | 自 | 来 | 水 | 来 | 自 | 海 | 上                   0   1    0    0   1    0    1   1   10表示不是词边界，1表示是词边界- **问题转化为：** 对于句子中的每一个字，进行二分类判断，正类表示这句话中，它是词边界，负类表示它不是词边界，这类问题被称为**序列标注问题** 标注数据、训练模型，使模型可以完成上述判断，那么这个模型，可以称为一个分词模型代码示例： [segmentation_based_on_rnn.py](./code/code1/segmentation_based_on_rnn.py ) 
**总结**: 目前，对于中文分词的研究在逐渐减少，有以下几方面原因：
 1. 目前的分词在由大部分情况下，效果已经比较理想，优化空间不大2. 分词即使发生错误，下游任务不是一定发生错误，所以不值得花大量精力优化分词3. 随着神经网络和预训练模型的兴起，中文任务逐渐不再需要分词，甚至不做分词，效果更好4. 解决不了的问题，是真的不好解决了**总结经验** 
1. 相同的任务有不同的算法可以完成2. 不同实现方式可能有相同的结果，但效率不同3. 不同的算法可能有不同的结果，但各有优劣4. 空间换时间，是一种常用的提升性能思路5. 多种算法组合使用，可能会获得更好的结果